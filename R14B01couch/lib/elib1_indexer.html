<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="latin1" />
    <title>elib1_indexer (lib) - R14B01couch - erldocs.com (Erlang Documentation)</title>
    <link type="text/css" rel="stylesheet" href="../erldocs.css" />
  </head>
  
  <body>

    <div id="sidebar" class="inactive">
      <input type="text" id="search" autocomplete="off" 
             placeholder="press TAB to search" />
      <ul id="results"> </ul>
    </div>

    <div id="content">
      <div style="margin:0px; padding:10px 20px;">
        

<h1>elib1_indexer</h1>
<h2 class="modsummary">A full-text indexing engine.</h2>
<div class="description">
<p>A full-text indexing engine. The functions in this library are
  modeled after the algorithms in the book "Managing Gigabytes" by
  I.A.Witten, A.Moffat and T.C. Bell, 2'nd edition.
  Morgan Kaufmann Publishing, 1999.
  <em>Unix Commands</em>
  <em>eindex</em>
  There are a number of top level UNIX commands to perform indexing.
  </p><pre class="sh_erlang">
  $ eindex -crawl Name
      Input Name.in     Output: Name.files and Name.crawl
  $ eindex -index Name
      Input: Name.crawl Output: Name.index
  $ eindex -dump Name
      Input Name     Output: Name.tmp
      example eindex -dump test2.crawl produces test2.crawl.tmp
  $ eindex -dumpIndex Name
      Input: Name.index Output: Name.index.tmp
  $ eindex -statstics Name
      Input: Name.index Output: Statistics
  $ eindex -search Name "String"
      Input Name.in
      Output: matching objects
      example: eindex -search test2 "property lists"
  $ eindex -help
      prints usage
  </pre><p>
  <em>-crawl</em>Is used to gather a collection of files
  together prior to indexing.
  The file <em>Name.in</em> contains a list of directories and file extensions
  which control the gathering phase. All matching files specified in the
  input file are read, compressed and appended into a single file
  called a <em>crawl</em>. This file will be rather large, depending upon the  
size of the scan - but it contains all the data we need for the subsequent  
indexing phases. In a typical gather phase, I collect 46,000 Erlang  
files on my disk and compress them into a single 120 MByte file.</p>
 
  <p><em>File Formats</em>
  <em>Crawl files</em>
  A file with the extension <em>.crawl</em> is a crawl file.
  A crawl file is a set of BFTs containing
  </p><pre class="sh_erlang">
  {Term:any(), Extension::string(), Md5Content::binry(), compressedContent::binary()}
  </pre>
 
  <p>The indexer uses a number or different file formats.
  These are contained in files with the extensions <em>.in</em>
  <em>.crawl</em> and <em>.index</em>.
  <em>Input Data</em>
  Files with the extension <em>.in</em> contain a list of
  tuples with a start directory and a file extension. For example the
  file <em>test1.in</em> in the examples/indexer directory contains
  the following:
  </p><pre class="sh_erlang">
  {"/Users/joe/code/elib2-1", ".erl"}.
  {"/Users/joe/msi/2005/erl/projects/supported", ".erl"}.
  </pre>
 
  <p>When the first phase of indexing occurs we crawl through the file
  system looking for all files under the root <em>/Users/joe/code/elib2.1</em>
  with the file extension <em>.erl</em>. Symbolic links are followed if
  they point within the root directory, but circular links are not followed.
  All the Erlang code found is compressed and appended to a so called
  "crawl" file. The crawl file is a sequence of tuples of the form
  </p><pre class="sh_erlang">
  {FileName::string(), Md5::binary(), CompressedContent::binary()}
  </pre><p>
  <em>Binary Tuple Format</em>
  Binary tuple formats (BTF) occurs a lot.
  If T is tuple, then the
  following binary written to disk is in BTF format:
  </p><pre class="sh_erlang">&lt;&lt;(size(tuple_to_binary(T)):32-unsigned-big-integer),
          tuple_to_binary(T)&gt;&gt;
  </pre><p>
  Stored on disk in binary tuple format (ie as a 4 byte length header,</p></div>
<div class="functions"><h4>Functions</h4><hr  />
<div class="function">
<h3 id="crawl_files/1">crawl_files(Name) -&gt; term()
</h3>


<div class="description"><span id="crawl_files-1"> </span>

<p>Reads Name.in and finds all the files in the input
  packing them in a file called Name.crawl. This calls
  init:stop() when it has finished.</p>
</div></div>
<div class="function">
<h3 id="do/1">do(Cmd) -&gt; term()
</h3>


<div class="description"><span id="do-1"> </span>
 </div></div>
<div class="function">
<h3 id="dump_index/1">dump_index(Name) -&gt; term()
</h3>


<div class="description"><span id="dump_index-1"> </span>
 </div></div>
<div class="function">
<h3 id="extract/2">extract(Name, I) -&gt; term()
</h3>


<div class="description"><span id="extract-2"> </span>

<p>given the name of a crawl file and a pointer into the
  crawl return the filename and content of the file stored in the
  crawl.</p>
</div></div>
<div class="function">
<h3 id="list_files/2">list_files(Name, L) -&gt; term()
</h3>


<div class="description"><span id="list_files-2"> </span>
 </div></div>
<div class="function">
<h3 id="lookup/2">lookup(Name, Str) -&gt; term()
</h3>


<div class="description"><span id="lookup-2"> </span>
 </div></div>
<div class="function">
<h3 id="make_index/2">make_index(Name, Top) -&gt; term()
</h3>


<div class="description"><span id="make_index-2"> </span>
 </div></div>
<div class="function">
<h3 id="q/2">q(Name, Str) -&gt; term()
</h3>


<div class="description"><span id="q-2"> </span>
 </div></div>
<div class="function">
<h3 id="q/3">q(Dir, Name, Str) -&gt; term()
</h3>


<div class="description"><span id="q-3"> </span>
 </div></div></div>

<authors>

<aname>Joe Armstrong</aname>
<email>erlang@gmail.com</email></authors>
      </div>
      <div id="funwrapper">
        <a id="viewfuns">View Functions</a>
        <ul id="funs"><li><a href="#crawl_files/1">crawl_files/1</a></li><li><a href="#do/1">do/1</a></li><li><a href="#dump_index/1">dump_index/1</a></li><li><a href="#extract/2">extract/2</a></li><li><a href="#list_files/2">list_files/2</a></li><li><a href="#lookup/2">lookup/2</a></li><li><a href="#make_index/2">make_index/2</a></li><li><a href="#q/2">q/2</a></li><li><a href="#q/3">q/3</a></li></ul>
      </div>
    </div>

    <script type="text/javascript">
      var CURRENT_ROOT = "../";
    </script>

    <script type="text/javascript" src="../jquery.js"></script>
    <script type="text/javascript" src="../erldocs_index.js"></script>
    <script type="text/javascript" src="../erldocs.js"></script>

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-44246018-1']);
      _gaq.push(['_trackPageview']);
      
      (function() {
        var ga = document.createElement('script');
        ga.src = ('https:' == document.location.protocol ?
          'https://ssl' : 'http://www') +
          '.google-analytics.com/ga.js';
        ga.setAttribute('async', 'true');
        document.documentElement.firstChild.appendChild(ga);
      })();
    </script>
  </body>
</html>

